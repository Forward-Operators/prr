version: 1
prompt:
  content_file: 'html_boilerplate'
services:
  gpt4_temp7:
    model: 'openai/chat/gpt-3.5-turbo'
    options:
      temperature: 0.7
  gpt4_temp0:
    model: 'openai/chat/gpt-3.5-turbo'
    options:
      temperature: 0
  c7:
    model: 'anthropic/complete/claude-v1.3'
    options:
      temperature: 0.7
  c0:
    model: 'anthropic/complete/claude-v1.3'
    options:
      temperature: 0
  options:
    max_tokens: 4000
