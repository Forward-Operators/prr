version: 1
prompt:
  content_file: '_html_boilerplate'
services:
  gpt4_temp7:
    model: 'openai/chat/gpt-4'
    options:
      temperature: 0.7
  gpt4_temp0:
    model: 'openai/chat/gpt-4'
    options:
      temperature: 0
  c7:
    model: 'anthropic/complete/claude-v1.3'
    options:
      temperature: 0.7
  c0:
    model: 'anthropic/complete/claude-v1.3'
    options:
      temperature: 0
  options:
    max_tokens: 4000
