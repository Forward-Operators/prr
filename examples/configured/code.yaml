version: 1
prompt:
  content: "def prompt_text_from_template(self, template):"
services:
  models:
    - 'bigcode/starcoder/starcoder'
  options:
    temperature: 0.7
    max_tokens: 250
    top_p: 0.9
    top_k: 40